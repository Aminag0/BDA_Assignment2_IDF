{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Loading and Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset:\n",
      "Index(['ARTICLE_ID', 'TITLE', 'SECTION_TITLE', 'SECTION_TEXT'], dtype='object')\n",
      "\n",
      "Sample rows from the dataset:\n",
      "   ARTICLE_ID      TITLE                 SECTION_TITLE  \\\n",
      "0           0  Anarchism                  Introduction   \n",
      "1           0  Anarchism     Etymology and terminology   \n",
      "2           0  Anarchism                       History   \n",
      "3           0  Anarchism  Anarchist schools of thought   \n",
      "4           0  Anarchism   Internal issues and debates   \n",
      "\n",
      "                                        SECTION_TEXT  \n",
      "0  \\n\\n\\n\\n\\n\\n'''Anarchism''' is a political phi...  \n",
      "1  \\n\\nThe term ''anarchism'' is a compound word ...  \n",
      "2  \\n\\n===Origins===\\nWoodcut from a Diggers docu...  \n",
      "3  \\nPortrait of philosopher Pierre-Joseph Proudh...  \n",
      "4  \\nconsistent with anarchist values is a contro...  \n",
      "First few rows of the extracted subset:\n",
      "   ARTICLE_ID                                       SECTION_TEXT\n",
      "0           0  \\n\\n\\n\\n\\n\\n'''Anarchism''' is a political phi...\n",
      "1           0  \\n\\nThe term ''anarchism'' is a compound word ...\n",
      "2           0  \\n\\n===Origins===\\nWoodcut from a Diggers docu...\n",
      "3           0  \\nPortrait of philosopher Pierre-Joseph Proudh...\n",
      "4           0  \\nconsistent with anarchist values is a contro...\n"
     ]
    }
   ],
   "source": [
    "# Section 1: Loading and Exploring the Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file_path = r\"C:\\Users\\DELL\\Desktop\\enwiki20170820.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the columns\n",
    "print(\"Columns in the dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Display a few sample rows\n",
    "print(\"\\nSample rows from the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Extract ARTICLE_ID and SECTION_TEXT columns\n",
    "df_subset = df[['ARTICLE_ID', 'SECTION_TEXT']]\n",
    "\n",
    "# Display the first few rows of the extracted subset\n",
    "print(\"First few rows of the extracted subset:\")\n",
    "print(df_subset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section 2 : Preprocess step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset:\n",
      "Index(['ARTICLE_ID', 'TITLE', 'SECTION_TITLE', 'SECTION_TEXT'], dtype='object')\n",
      "\n",
      "Sample rows from the dataset:\n",
      "   ARTICLE_ID      TITLE                 SECTION_TITLE  \\\n",
      "0           0  Anarchism                  Introduction   \n",
      "1           0  Anarchism     Etymology and terminology   \n",
      "2           0  Anarchism                       History   \n",
      "3           0  Anarchism  Anarchist schools of thought   \n",
      "4           0  Anarchism   Internal issues and debates   \n",
      "\n",
      "                                        SECTION_TEXT  \n",
      "0  \\n\\n\\n\\n\\n\\n'''Anarchism''' is a political phi...  \n",
      "1  \\n\\nThe term ''anarchism'' is a compound word ...  \n",
      "2  \\n\\n===Origins===\\nWoodcut from a Diggers docu...  \n",
      "3  \\nPortrait of philosopher Pierre-Joseph Proudh...  \n",
      "4  \\nconsistent with anarchist values is a contro...  \n",
      "\n",
      "First few rows of the preprocessed text:\n",
      "0    anarchism political philosophy advocates selfg...\n",
      "1    term anarchism compound word composed word ana...\n",
      "2    origins woodcut diggers document william evera...\n",
      "3    portrait philosopher pierrejoseph proudhon 180...\n",
      "4    consistent anarchist values controversial subj...\n",
      "Name: SECTION_TEXT_CLEAN, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Section 2 : Preprocess step 1\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords from NLTK\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define a function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Check if the text is NaN\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove non-alphanumeric characters and punctuation\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Join the tokens back into a string\n",
    "    preprocessed_text = ' '.join(filtered_tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "csv_file_path = \"C:/Users/DELL/Desktop/enwiki20170820.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display columns in the dataset\n",
    "print(\"Columns in the dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Display sample rows from the dataset\n",
    "print(\"\\nSample rows from the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Apply text preprocessing to the SECTION_TEXT column\n",
    "df['SECTION_TEXT_CLEAN'] = df['SECTION_TEXT'].apply(preprocess_text)\n",
    "\n",
    "# Display the first few rows of the preprocessed text\n",
    "print(\"\\nFirst few rows of the preprocessed text:\")\n",
    "print(df['SECTION_TEXT_CLEAN'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Save the preprocessed data in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data has been saved to: preprocessed_data.csv\n",
      "\n",
      "Saved preprocessed data:\n",
      "   ARTICLE_ID                                 SECTION_TEXT_CLEAN\n",
      "0           0  anarchism political philosophy advocates selfg...\n",
      "1           0  term anarchism compound word composed word ana...\n",
      "2           0  origins woodcut diggers document william evera...\n",
      "3           0  portrait philosopher pierrejoseph proudhon 180...\n",
      "4           0  consistent anarchist values controversial subj...\n"
     ]
    }
   ],
   "source": [
    "# Define the path for the new file to store the preprocessed data\n",
    "output_file_path = \"preprocessed_data.csv\"\n",
    "\n",
    "# Select the required columns (ARTICLE_ID and SECTION_TEXT_CLEAN)\n",
    "df_preprocessed = df[['ARTICLE_ID', 'SECTION_TEXT_CLEAN']]\n",
    "\n",
    "# Save the preprocessed data to the new file\n",
    "df_preprocessed.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Print a message indicating that the data has been saved successfully\n",
    "print(\"Preprocessed data has been saved to:\", output_file_path)\n",
    "\n",
    "# Load the saved preprocessed data from the CSV file\n",
    "df_saved = pd.read_csv(output_file_path)\n",
    "\n",
    "# Print the first few rows of the saved preprocessed data\n",
    "print(\"\\nSaved preprocessed data:\")\n",
    "print(df_saved.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
